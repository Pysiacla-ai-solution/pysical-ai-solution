# job_lead.py ìƒì„±
import time
import os
import sys

def log(msg):
    print(f"[Lead/Debug] {msg}", flush=True)

log(f"ğŸ”¥ ê¸´ê¸‰ ë””ë²„ê¹… ì‹œì‘! (PID: {os.getpid()})")

try:
    import torch
    if torch.cuda.is_available():
        # 10GB VRAM í• ë‹¹
        # 2,500,000,000 * 4 bytes â‰ˆ 10GB
        tensor_size = 2_500_000_000
        try:
            data = torch.empty(tensor_size, dtype=torch.float32, device='cuda')
            log(f"âœ… VRAM 10GB í™•ë³´ ì„±ê³µ: {torch.cuda.get_device_name(0)}")
        except RuntimeError as e:
            log(f"âŒ VRAM ë¶€ì¡± (OOM): {e}")
            sys.exit(1) # ì‹¤íŒ¨ ì²˜ë¦¬
    else:
        log("âš ï¸ CUDA ì—†ìŒ: CPU ëª¨ë“œ")
except ImportError:
    log("âš ï¸ PyTorch ì—†ìŒ")

# 20ì´ˆ ë§Œì— í›„ë”± ëëƒ„
total_time = 20
for i in range(total_time):
    log(f"ë²„ê·¸ ì¡ëŠ” ì¤‘... {i+1}/{total_time}ì´ˆ")
    time.sleep(1)

log("ğŸ‰ ë””ë²„ê¹… ì™„ë£Œ (ì„œë¹„ìŠ¤ ì •ìƒí™”)")